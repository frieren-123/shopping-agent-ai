import os
import json
import sys
from openai import OpenAI
from dotenv import load_dotenv

# å°è¯•å¯¼å…¥ ContextManager
try:
    from src.context.context_manager import ContextManager
except ImportError:
    # å¦‚æœç›´æ¥è¿è¡Œæ­¤è„šæœ¬ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´è·¯å¾„
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    try:
        from src.context.context_manager import ContextManager
    except ImportError:
        print("âš ï¸ æ— æ³•å¯¼å…¥ ContextManagerï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
        ContextManager = None

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def get_llm_client():
    api_key = os.getenv("LLM_API_KEY")
    base_url = os.getenv("LLM_BASE_URL")
    
    if not api_key or "xxxx" in api_key:
        raise ValueError("è¯·å…ˆåœ¨ .env æ–‡ä»¶ä¸­é…ç½®æ­£ç¡®çš„ LLM_API_KEY")
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    return OpenAI(api_key=api_key, base_url=base_url)

def ask_clarifying_questions(product_name):
    """
    æ ¹æ®å•†å“åç§°ç”Ÿæˆ 3 ä¸ªå…³é”®çš„æ¾„æ¸…é—®é¢˜ï¼Œä»¥ä¾¿æ›´ç²¾å‡†åœ°ç­›é€‰ã€‚
    """
    client = get_llm_client()
    model = os.getenv("LLM_MODEL", "gpt-3.5-turbo")
    
    prompt = f"""
    ç”¨æˆ·æƒ³è¦è´­ä¹°ï¼š"{product_name}"ã€‚
    ä¸ºäº†å¸®ç”¨æˆ·ç­›é€‰å‡ºæœ€åˆé€‚çš„å•†å“ï¼Œè¯·æå‡º 3 ä¸ªæœ€é‡è¦çš„æ¾„æ¸…é—®é¢˜ï¼ˆä¾‹å¦‚é¢„ç®—ã€å…·ä½“åŠŸèƒ½ã€ä½¿ç”¨åœºæ™¯ç­‰ï¼‰ã€‚
    
    è¯·ç›´æ¥è¿”å›ä¸€ä¸ª JSON å­—ç¬¦ä¸²æ•°ç»„ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
    ["é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3"]
    ä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ã€‚
    """
    
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è´­ç‰©é¡¾é—®ã€‚"},
                {"role": "user", "content": prompt}
            ]
        )
        content = response.choices[0].message.content.strip()
        content = content.replace("```json", "").replace("```", "")
        questions = json.loads(content)
        return questions
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆé—®é¢˜å¤±è´¥: {e}")
        return []

def filter_products(user_requirements, top_n=5):
    """
    ç¬¬ä¸€é˜¶æ®µï¼šæ™ºèƒ½åˆç­›
    è¯»å– search_results.jsonï¼Œæ ¹æ®ç”¨æˆ·éœ€æ±‚ç­›é€‰å‡º Top N
    """
    input_file = "data/search_results.json"
    if not os.path.exists(input_file):
        print(f"æ–‡ä»¶ {input_file} ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œçˆ¬è™«æŠ“å–åˆ—è¡¨ã€‚")
        return []

    with open(input_file, "r", encoding="utf-8") as f:
        products = json.load(f)

    if not products:
        print("å•†å“åˆ—è¡¨ä¸ºç©ºã€‚")
        return []

    print(f"æ­£åœ¨å¯¹ {len(products)} ä¸ªå•†å“è¿›è¡Œåˆç­›ï¼Œéœ€æ±‚ï¼š{user_requirements}ï¼Œç›®æ ‡æ•°é‡ï¼š{top_n}")
    
    client = get_llm_client()
    model = os.getenv("LLM_MODEL", "gpt-3.5-turbo")

    # ç®€åŒ–æ•°æ®ä»¥èŠ‚çœ Token
    products_summary = []
    for p in products[:100]: # é™åˆ¶å‰ 100 ä¸ªï¼Œé¿å… token æº¢å‡º
        products_summary.append({
            "id": p.get("id"),
            "title": p.get("title"),
            "price": p.get("price"),
            "sales": p.get("deal_count"),
            "shop": p.get("shop")
        })

    # è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡ (MineContext)
    user_context_prompt = ""
    if ContextManager:
        ctx_mgr = ContextManager()
        user_context_prompt = ctx_mgr.get_critical_thinking_prompt()

    prompt = f"""
    {user_context_prompt}

    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”µå•†é€‰å“ä¸“å®¶ã€‚ç”¨æˆ·æƒ³ä¹°ï¼š"{user_requirements}"ã€‚
    
    ä¸‹é¢æ˜¯æŠ“å–åˆ°çš„å•†å“åˆ—è¡¨ï¼ˆJSONæ ¼å¼ï¼‰ï¼š
    {json.dumps(products_summary, ensure_ascii=False)}
    
    è¯·æ ¹æ®ç”¨æˆ·çš„é¢„ç®—å’Œéœ€æ±‚ï¼Œç­›é€‰å‡ºæœ€å€¼å¾—æ·±å…¥ç ”ç©¶çš„ {top_n} ä¸ªå•†å“ã€‚
    
    ### æ€è€ƒæ­¥éª¤ (Chain of Thought):
    1. **åˆ†æéœ€æ±‚**: ç”¨æˆ·çš„æ ¸å¿ƒç—›ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿé¢„ç®—èŒƒå›´æ˜¯å¤šå°‘ï¼Ÿ
    2. **æ’é™¤æ³•**: å‰”é™¤æ˜æ˜¾ä¸ç¬¦åˆé¢„ç®—ã€è¯„åˆ†è¿‡ä½æˆ–ä¸å…³é”®è¯ä¸ç¬¦çš„å•†å“ã€‚
    3. **ä¼˜é€‰æ³•**: åœ¨å‰©ä½™å•†å“ä¸­ï¼Œå¯»æ‰¾æ€§ä»·æ¯”æœ€é«˜ã€å“ç‰Œå£ç¢‘å¥½æˆ–æœ‰ç‹¬ç‰¹å–ç‚¹çš„å•†å“ã€‚
    4. **é˜²å‘æ£€æŸ¥**: æ£€æŸ¥æ˜¯å¦æœ‰è™šå‡å®£ä¼ æˆ–â€œç½‘çº¢â€æº¢ä»·è¿‡é«˜çš„è¿¹è±¡ã€‚

    ### è¾“å‡ºè¦æ±‚:
    è¯·è¿”å›ä¸€ä¸ª JSON æ•°ç»„ï¼ŒåªåŒ…å«è¿™ {top_n} ä¸ªå•†å“çš„ IDã€‚
    æ ¼å¼ä¸¥æ ¼å¦‚ä¸‹ï¼š
    ["id1", "id2", "id3", "id4", "id5"]
    
    **æ³¨æ„**: ä¸è¦è¿”å›ä»»ä½• Markdown æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰ï¼Œä¸è¦è¿”å›ä»»ä½•è§£é‡Šæ–‡å­—ï¼Œåªè¿”å›çº¯ JSON å­—ç¬¦ä¸²ã€‚
    """

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåªè¾“å‡º JSON çš„åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2 # é™ä½éšæœºæ€§ï¼Œæé«˜ JSON æ ¼å¼ç¨³å®šæ€§
        )
        
        content = response.choices[0].message.content.strip()
        # æ¸…ç†å¯èƒ½çš„ markdown æ ‡è®°
        content = content.replace("```json", "").replace("```", "").strip()
        
        print(f"ğŸ” LLM åŸå§‹å“åº”: {content[:100]}...") # Debug log

        try:
            top_ids = json.loads(content)
        except json.JSONDecodeError:
            print("âš ï¸ LLM è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œå°è¯•ä¿®å¤...")
            # å°è¯•ç®€å•çš„æ­£åˆ™æå–
            import re
            top_ids = re.findall(r'"(\d+)"', content)
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä»¥ç¡®ä¿åŒ¹é…
        top_ids = [str(i) for i in top_ids]
        
        print(f"LLM é€‰ä¸­çš„ ID: {top_ids}")
        
        top_products = [p for p in products if str(p.get("id")) in top_ids]
        
        # --- Fallback æœºåˆ¶ ---
        if not top_products:
            print("âš ï¸ LLM æœªé€‰ä¸­ä»»ä½•å•†å“ (æˆ– ID åŒ¹é…å¤±è´¥)ã€‚")
            print("ğŸ”„ å¯åŠ¨è‡ªåŠ¨å…œåº•æœºåˆ¶ï¼šæŒ‰é”€é‡å’Œä»·æ ¼æ’åºé€‰å‡º Top 5...")
            
            # ç®€å•çš„æ’åºé€»è¾‘ï¼šé”€é‡é«˜ä¼˜å…ˆ
            def sort_key(p):
                try:
                    return int(p.get("deal_count", "0").replace("+", "").replace("ä¸‡", "0000"))
                except:
                    return 0
            
            sorted_products = sorted(products, key=sort_key, reverse=True)
            top_products = sorted_products[:top_n]
            print(f"âœ… å…œåº•é€‰ä¸­ {len(top_products)} ä¸ªå•†å“")
        # ---------------------

        with open("data/top_candidates.json", "w", encoding="utf-8") as f:
            json.dump(top_products, f, ensure_ascii=False, indent=2)
            
        print(f"åˆç­›å®Œæˆï¼é€‰å‡º {len(top_products)} ä¸ªå€™é€‰å•†å“ã€‚")
        for p in top_products:
            print(f"   - {p['title']} (Â¥{p['price']})")
            
        return top_products

    except Exception as e:
        print(f"åˆç­›å¤±è´¥: {e}")
        # å‘ç”Ÿå¼‚å¸¸æ—¶ä¹Ÿè¿›è¡Œå…œåº•
        print("ğŸ”„ å¼‚å¸¸å…œåº•ï¼šæŒ‰é»˜è®¤é¡ºåºé€‰å–å‰ 5 ä¸ª")
        top_products = products[:top_n]
        with open("data/top_candidates.json", "w", encoding="utf-8") as f:
            json.dump(top_products, f, ensure_ascii=False, indent=2)
        return top_products

def analyze_products():
    """
    ç¬¬äºŒé˜¶æ®µï¼šæ·±åº¦åˆ†æ
    1. è°ƒç”¨ parser è§£æ data/details/ ä¸‹çš„ HTML
    2. è°ƒç”¨ LLM ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    """
    # 1. å…ˆè¿è¡Œè§£æå™¨
    print("æ­£åœ¨è§£æè¯¦æƒ…é¡µæ•°æ®...")
    # åŠ¨æ€å¯¼å…¥ä»¥é¿å…å¾ªç¯ä¾èµ–
    try:
        sys.path.append(os.path.dirname(os.path.abspath(__file__)))
        from product_parser import parse_all
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å¤ç”¨ product_parser.pyï¼Œè®©å®ƒå»è§£æ data/details ç›®å½•
        products = parse_all(input_dir="data/details")
    except ImportError as e:
        print(f"å¯¼å…¥è§£æå™¨å¤±è´¥: {e}")
        return

    if not products:
        print("æ²¡æœ‰è§£æåˆ°è¯¦æƒ…æ•°æ®ï¼Œè¯·æ£€æŸ¥ data/details/ ç›®å½•ä¸‹æ˜¯å¦æœ‰ JSON æ–‡ä»¶ã€‚")
        return

    # åŠ è½½åŸå§‹é“¾æ¥ä¿¡æ¯
    url_map = {}
    if os.path.exists("data/top_candidates.json"):
        with open("data/top_candidates.json", "r", encoding="utf-8") as f:
            candidates = json.load(f)
            for c in candidates:
                url_map[str(c.get("id"))] = c.get("link")

    # å°†é“¾æ¥æ³¨å…¥åˆ°è§£æåçš„æ•°æ®ä¸­
    for p in products:
        # source_file æ ¼å¼å¦‚ "123456.json"
        p_id = p.get("source_file", "").replace(".json", "")
        if p_id in url_map:
            p["url"] = url_map[p_id]
        else:
            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•æ„é€ é»˜è®¤é“¾æ¥
            p["url"] = f"https://item.taobao.com/item.htm?id={p_id}"

    client = get_llm_client()
    model = os.getenv("LLM_MODEL", "gpt-3.5-turbo")

    print(f"æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹ ({model}) è¿›è¡Œæ·±åº¦åˆ†æï¼Œè¯·ç¨å€™...")

    # è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡ (MineContext)
    user_context_prompt = ""
    if ContextManager:
        ctx_mgr = ContextManager()
        user_context_prompt = ctx_mgr.get_critical_thinking_prompt()

    # æ„å»º Prompt
    products_str = json.dumps(products, ensure_ascii=False, indent=2)
    
    prompt = f"""
    {user_context_prompt}

    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç”µå•†è´­ç‰©é¡¾é—®ã€‚æˆ‘ä»¬å·²ç»ç»è¿‡äº†åˆç­›ï¼Œç°åœ¨è¿›å…¥å†³èµ›åœˆã€‚
    ä»¥ä¸‹æ˜¯ 5 ä¸ªå€™é€‰å•†å“çš„è¯¦ç»†æ•°æ®ï¼ˆåŒ…å«è¯„è®ºã€å‚æ•°ç­‰ï¼‰ï¼š
    
    {products_str}
    
    è¯·ç”Ÿæˆä¸€ä»½è¯¦ç»†çš„è´­ä¹°å†³ç­–æŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
    
    ## 1. å€™é€‰å•†å“æ¦‚è§ˆ
    ï¼ˆåˆ—å‡ºè¿™å‡ ä¸ªå•†å“çš„åŸºæœ¬ä¿¡æ¯ï¼Œåšä¸€ä¸ªç®€å•çš„ Markdown è¡¨æ ¼å¯¹æ¯”ä»·æ ¼ã€é”€é‡ã€åº—é“ºã€‚**é‡è¦ï¼šè¯·åœ¨è¡¨æ ¼ä¸­çš„å•†å“åç§°ä¸ŠåŠ ä¸Šè¶…é“¾æ¥ï¼Œæ ¼å¼ä¸º [å•†å“å](URL)**ï¼‰
    
    ## 2. æ·±åº¦ç‚¹è¯„
    ï¼ˆå¯¹æ¯ä¸ªå•†å“è¿›è¡Œç‚¹è¯„ï¼Œé‡ç‚¹åˆ†æï¼š
    - **ä¼˜ç‚¹**ï¼šåŸºäºè¯„è®ºå’Œå‚æ•°ã€‚
    - **ç¼ºç‚¹/é£é™©**ï¼šåŸºäºå·®è¯„æˆ–å‚æ•°çŸ­æ¿ã€‚
    - **é€‚åˆäººç¾¤**ï¼šè°åº”è¯¥ä¹°å®ƒï¼Ÿï¼‰
    
    ## 3. æœ€ç»ˆæ¨è (Winner)
    - **é¦–é€‰æ¨è**ï¼šç»¼åˆæ€§ä»·æ¯”æœ€é«˜çš„é‚£ä¸ªã€‚ï¼ˆ**è¯·åŠ¡å¿…é™„ä¸Šè´­ä¹°é“¾æ¥**ï¼‰
    - **å¤‡é€‰æ¨è**ï¼šå¦‚æœæœ‰ç‰¹å®šéœ€æ±‚ï¼ˆå¦‚é¢„ç®—æ›´ä½æˆ–æ€§èƒ½æ›´å¼ºï¼‰çš„é€‰æ‹©ã€‚ï¼ˆ**è¯·åŠ¡å¿…é™„ä¸Šè´­ä¹°é“¾æ¥**ï¼‰
    - **ç†ç”±**ï¼šä¸ºä»€ä¹ˆé€‰å®ƒï¼Ÿ
    
    è¯·ç”¨ Markdown æ ¼å¼è¾“å‡ºã€‚
    """

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå®¢è§‚ã€çŠ€åˆ©ã€ä¸è¯´åºŸè¯çš„è´­ç‰©å†³ç­–åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ]
        )
        
        report = response.choices[0].message.content
        
        # ä¿å­˜æŠ¥å‘Š
        with open("data/final_report.md", "w", encoding="utf-8") as f:
            f.write(report)
            
        # ç”Ÿæˆ HTML æŠ¥å‘Š
        generate_html_report(report)
            
        print("\n" + "="*30)
        print("æœ€ç»ˆè´­ä¹°æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
        print("="*30 + "\n")
        print(report)
        print("\n" + "="*30)
        print("æŠ¥å‘Šå·²ä¿å­˜è‡³ data/final_report.md å’Œ data/final_report.html")

    except Exception as e:
        print(f"è°ƒç”¨å¤§æ¨¡å‹å¤±è´¥: {e}")

def generate_html_report(markdown_content):
    """
    å°† Markdown æŠ¥å‘Šè½¬æ¢ä¸ºç¾è§‚çš„ HTML é¡µé¢
    """
    html_template = """
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI è´­ç‰©å†³ç­–æŠ¥å‘Š</title>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max_width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f9f9f9;
        }
        .container {
            background-color: #fff;
            padding: 40px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        h1, h2, h3 {
            color: #2c3e50;
            border-bottom: 2px solid #eee;
            padding-bottom: 10px;
        }
        h1 { text-align: center; border-bottom: none; color: #e67e22; }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            padding: 12px;
            border: 1px solid #ddd;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
            font-weight: bold;
        }
        tr:nth-child(even) { background-color: #f8f8f8; }
        a {
            color: #3498db;
            text-decoration: none;
        }
        a:hover { text-decoration: underline; }
        blockquote {
            border-left: 4px solid #e67e22;
            padding-left: 15px;
            color: #7f8c8d;
            background-color: #fff5e6;
            padding: 10px;
        }
        .footer {
            text-align: center;
            margin-top: 40px;
            font-size: 0.8em;
            color: #7f8c8d;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ›’ AI è´­ç‰©å†³ç­–æŠ¥å‘Š</h1>
        <div id="content"></div>
        <div class="footer">
            Generated by AI Shopping Agent
        </div>
    </div>
    <script>
        const markdown = `MARKDOWN_PLACEHOLDER`;
        document.getElementById('content').innerHTML = marked.parse(markdown);
    </script>
</body>
</html>
    """
    
    # Escape backticks in markdown content to avoid breaking JS string
    safe_markdown = markdown_content.replace("`", "\\`").replace("${", "\\${")
    
    html_content = html_template.replace("MARKDOWN_PLACEHOLDER", safe_markdown)
    
    with open("data/final_report.html", "w", encoding="utf-8") as f:
        f.write(html_content)

def analyze_trends(zhihu_data, original_keyword):
    """
    æ ¹æ®çŸ¥ä¹çš„è°ƒç ”ç»“æœï¼Œä¼˜åŒ–æœç´¢å…³é”®è¯
    """
    if not zhihu_data:
        return original_keyword
        
    client = get_llm_client()
    model = os.getenv("LLM_MODEL", "gpt-3.5-turbo")
    
    data_str = json.dumps(zhihu_data, ensure_ascii=False, indent=2)
    
    prompt = f"""
    ç”¨æˆ·æƒ³ä¹°ï¼š"{original_keyword}"ã€‚
    æˆ‘å…ˆåœ¨çŸ¥ä¹/å°çº¢ä¹¦ä¸Šè°ƒç ”äº†ä¸€ä¸‹ï¼Œæ‰¾åˆ°äº†ä»¥ä¸‹çƒ­é—¨æ–‡ç« æ ‡é¢˜å’Œæ‘˜è¦ï¼š
    {data_str}
    
    è¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š
    1. **æ‰¹åˆ¤æ€§æ€ç»´**ï¼šè¯·è­¦æƒ•è½¯æ–‡å¹¿å‘Šï¼ˆSoft Adsï¼‰ã€‚å¦‚æœæ‰€æœ‰æ–‡ç« éƒ½ä¸€é¢å€’åœ°æ¨èæŸä¸ªå“ç‰Œï¼Œè¿™å¯èƒ½æ˜¯è¥é”€æ”»åŠ¿ã€‚
    2. **æå–çœŸå®éœ€æ±‚**ï¼šä»ç”¨æˆ·çš„è®¨è®ºä¸­ï¼Œæå–å‡ºä»–ä»¬çœŸæ­£å…³å¿ƒçš„**æ ¸å¿ƒå‚æ•°**ï¼ˆå¦‚â€œæˆåˆ†å®‰å…¨â€ã€â€œæ— ç¡…æ²¹â€ï¼‰ï¼Œè€Œä¸æ˜¯ç›²ç›®è·Ÿéšå“ç‰Œã€‚
    3. **ç”Ÿæˆå…³é”®è¯**ï¼šç»“åˆåŸå§‹éœ€æ±‚ï¼Œç”Ÿæˆä¸€ä¸ªæ›´ç²¾å‡†çš„æ·˜å®/äº¬ä¸œæœç´¢å…³é”®è¯ã€‚
       - **å¿…é¡»ç®€çŸ­**ï¼šä¸è¦è¶…è¿‡ 3 ä¸ªè¯ï¼ˆä¾‹å¦‚ "æ‰‹æœº éªé¾™8Gen3" è€Œä¸æ˜¯ "2024å¹´æœ€æ–°æ¬¾æ­è½½éªé¾™8Gen3å¤„ç†å™¨çš„æ‰‹æœº"ï¼‰ã€‚
       - **å»é™¤éå…³é”®è¯**ï¼šå»æ‰ "æ¨è"ã€"æ±‚è´­"ã€"æ€ä¹ˆæ ·"ã€"å…¨ä»·ä½" ç­‰æ— æ„ä¹‰è¯æ±‡ã€‚
       - å¦‚æœä½ è§‰å¾—çƒ­é—¨å“ç‰Œæœ‰è¥é”€å«Œç–‘ï¼Œè¯·ç”Ÿæˆä¸€ä¸ª**åŸºäºåŠŸèƒ½/æˆåˆ†**çš„å…³é”®è¯ï¼ˆå¦‚â€œæ°¨åŸºé…¸æ´—å‘æ°´ æ•æ„Ÿè‚Œâ€ï¼‰ï¼Œè€Œä¸æ˜¯å“ç‰Œè¯ã€‚
       - å¦‚æœçƒ­é—¨å“ç‰Œç¡®å®å£ç¢‘å¥½ï¼Œå¯ä»¥åŒ…å«å“ç‰Œåã€‚
    
    ä¾‹å¦‚ï¼š
    - åŸéœ€æ±‚ï¼š"æ´—å‘æ°´" -> è¾“å‡ºï¼š"å¼±é…¸æ€§æ´—å‘æ°´ æ§æ²¹"
    - åŸéœ€æ±‚ï¼š"é«˜æ€§ä»·æ¯”æ‰‹æœº" -> è¾“å‡ºï¼š"æ‰‹æœº éªé¾™8Gen2"
    
    è¯·ç›´æ¥è¿”å›å…³é”®è¯ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€‚
    """
    
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœç´¢ä¼˜åŒ–ä¸“å®¶ã€‚"},
                {"role": "user", "content": prompt}
            ]
        )
        refined_keyword = response.choices[0].message.content.strip()
        print(f"ğŸ§  AI ä¼˜åŒ–åçš„æœç´¢è¯: {refined_keyword}")
        return refined_keyword
    except Exception as e:
        print(f"âš ï¸ å…³é”®è¯ä¼˜åŒ–å¤±è´¥: {e}")
        return original_keyword

def extract_info_from_markdown(markdown_text):
    """
    ä½¿ç”¨ LLM ä» Markdown æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–çš„å•†å“ä¿¡æ¯ã€‚
    """
    client = get_llm_client()
    model = os.getenv("LLM_MODEL", "gpt-3.5-turbo")
    
    # æˆªå–å‰ 50000 ä¸ªå­—ç¬¦ï¼Œé¿å… Token æº¢å‡º (é€šå¸¸å•†å“åˆ—è¡¨åœ¨å‰éƒ¨)
    truncated_text = markdown_text[:50000]
    
    prompt = f"""
    ä»¥ä¸‹æ˜¯ç”µå•†æœç´¢ç»“æœé¡µé¢çš„ Markdown å†…å®¹ï¼š
    
    {truncated_text}
    
    è¯·ä»ä¸­æå–å•†å“åˆ—è¡¨ä¿¡æ¯ã€‚
    è¯·è¿”å›ä¸€ä¸ª JSON æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
    - "title": å•†å“æ ‡é¢˜ (å­—ç¬¦ä¸²)
    - "price": ä»·æ ¼ (å­—ç¬¦ä¸²ï¼Œå¦‚ "299.00")
    - "shop": åº—é“ºåç§° (å­—ç¬¦ä¸²ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™å¡« "æœªçŸ¥")
    - "link": å•†å“é“¾æ¥ (å­—ç¬¦ä¸²ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™å¡« "")
    
    åªæå–å‰ 10 ä¸ªæœ€ç›¸å…³çš„å•†å“å³å¯ã€‚
    è¯·ç›´æ¥è¿”å› JSON æ•°ç»„ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°æˆ–å…¶ä»–æ–‡å­—ã€‚
    """
    
    try:
        print(f"   ...å‘ LLM å‘é€è¯·æ±‚ (é•¿åº¦: {len(truncated_text)} chars)...")
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®æå–ä¸“å®¶ï¼Œåªè¾“å‡º JSONã€‚"},
                {"role": "user", "content": prompt}
            ],
            timeout=60  # è®¾ç½® 60 ç§’è¶…æ—¶
        )
        
        content = response.choices[0].message.content.strip()
        content = content.replace("```json", "").replace("```", "").strip()
        
        products = json.loads(content)
        
        if not products:
            print(f"   âš ï¸ LLM è¿”å›äº†ç©ºåˆ—è¡¨ã€‚åŸå§‹å“åº”: {content[:200]}...")

        # ç®€å•çš„åå¤„ç†ï¼šç¡®ä¿ ID å­˜åœ¨
        for p in products:
            if "id" not in p:
                # å°è¯•ä»é“¾æ¥æå– ID
                import re
                link = p.get("link", "")
                id_match = re.search(r'(\d+)\.html', link)
                if id_match:
                    p["id"] = id_match.group(1)
                else:
                    # éšæœºç”Ÿæˆä¸€ä¸ª ID é˜²æ­¢æŠ¥é”™
                    import random
                    p["id"] = str(random.randint(100000, 999999))
            
            p["platform"] = "JD (AI)"
            p["deal_count"] = "æœªçŸ¥" # åˆ—è¡¨é¡µé€šå¸¸éš¾æå–é”€é‡
            
        return products
        
    except Exception as e:
        print(f"âš ï¸ AI æå–å¤±è´¥: {e}")
        return []

if __name__ == "__main__":
    if len(sys.argv) > 1:
        cmd = sys.argv[1]
        if cmd == "filter":
            req = sys.argv[2] if len(sys.argv) > 2 else "é«˜æ€§ä»·æ¯”å•†å“"
            filter_products(req)
        elif cmd == "analyze":
            analyze_products()
        else:
            print("æœªçŸ¥å‘½ä»¤ã€‚ç”¨æ³•: python src/llm_analyzer.py [filter <éœ€æ±‚> | analyze]")
    else:
        print("1. è¿è¡Œæ™ºèƒ½åˆç­› (Filter)")
        print("2. è¿è¡Œæ·±åº¦åˆ†æ (Analyze - éœ€å…ˆæœ‰ details HTML)")
        choice = input("è¯·é€‰æ‹© (1/2): ").strip()
        
        if choice == "1":
            req = input("è¯·è¾“å…¥ä½ çš„å…·ä½“éœ€æ±‚ (å¦‚ '100å…ƒä»¥å†…é™å™ªè€³æœº'): ").strip()
            filter_products(req)
        elif choice == "2":
            analyze_products()
        else:
            print("æ— æ•ˆé€‰æ‹©")
