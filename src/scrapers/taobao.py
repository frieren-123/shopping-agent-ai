import os
import time
import random
import json
import re
from playwright.sync_api import sync_playwright
from .base import BaseScraper

class TaobaoScraper(BaseScraper):
    def __init__(self):
        self.global_products = []
        self.global_details = {}
        self.keyword = "" # Store keyword for filtering

    def _handle_search_response(self, response):
        # æ”¾å®½æ‹¦æˆªæ¡ä»¶ï¼šåªè¦æ˜¯ API è¯·æ±‚æˆ–è€…åŒ…å« search å…³é”®å­—
        resource_type = response.request.resource_type
        if resource_type in ["xhr", "fetch", "script"]:
            try:
                content_type = response.headers.get("content-type", "")
                if "json" in content_type or "javascript" in content_type:
                    text = response.text()
                    
                    # å°è¯•è§£æ mtopjsonp
                    if text.strip().startswith("mtopjsonp") or text.strip().startswith("jsonp"):
                        match = re.search(r'\((.*)\)', text)
                        if match:
                            text = match.group(1)

                    if '"raw_title"' in text or '"view_price"' in text or '"title":' in text:
                        if "suggest" in response.url: return 

                        # print(f"   âš¡ æ•è·åˆ°ç–‘ä¼¼å•†å“æ•°æ®: {response.url[:60]}...")
                        
                        # å°è¯•ç›´æ¥ JSON è§£æ (æ›´å‡†ç¡®)
                        try:
                            data = json.loads(text)
                            # æ·˜å® API ç»“æ„å¤šå˜ï¼Œå°è¯•å‡ ç§å¸¸è§è·¯å¾„
                            # 1. mods.itemlist.data.auctions
                            itemlist = data.get("mods", {}).get("itemlist", {}).get("data", {}).get("auctions", [])
                            if not itemlist:
                                # 2. itemsArray
                                itemlist = data.get("itemsArray", [])
                            
                            if itemlist:
                                count = 0
                                seen_ids = set(p['id'] for p in self.global_products)
                                for item in itemlist:
                                    nid = item.get("nid") or item.get("item_id")
                                    if not nid or nid in seen_ids: continue
                                    
                                    title = item.get("raw_title") or item.get("title", "")
                                    price = item.get("view_price") or item.get("price", "0")
                                    sales = item.get("view_sales") or item.get("sold", "0")
                                    link = item.get("detail_url") or item.get("url", "")
                                    
                                    # ç§»é™¤ä¸¥æ ¼çš„å…³é”®è¯è¿‡æ»¤ï¼Œä¿¡ä»»æ·˜å®çš„æœç´¢ç»“æœ
                                    # if self.keyword[:1] not in title: continue
                                    
                                    # è¯†åˆ«å¤©çŒ«
                                    shop_name = item.get("nick", "æ·˜å®åº—é“º")
                                    is_tmall = False
                                    if "æ——èˆ°åº—" in shop_name or "ä¸“å–åº—" in shop_name or item.get("user_type") == "1": # user_type 1 é€šå¸¸æ˜¯å¤©çŒ«
                                        is_tmall = True
                                        shop_name = "ğŸ”´ [å¤©çŒ«] " + shop_name
                                    
                                    self.global_products.append({
                                        "id": nid,
                                        "title": title,
                                        "price": price,
                                        "link": link if link.startswith("http") else "https:" + link,
                                        "shop": shop_name,
                                        "deal_count": sales,
                                        "platform": "Tmall" if is_tmall else "Taobao"
                                    })
                                    seen_ids.add(nid)
                                    count += 1
                                if count > 0:
                                    print(f"   âœ… é€šè¿‡ API æ‹¦æˆªè§£æäº† {count} ä¸ªå•†å“")
                                    return
                        except:
                            pass

                        # å¦‚æœ JSON è§£æå¤±è´¥ï¼Œå›é€€åˆ°æ­£åˆ™æå–
                        titles = re.findall(r'"raw_title":"([^"]+)"', text)
                        if not titles:
                            titles = re.findall(r'"title":"([^"]+)"', text)
                        
                        prices = re.findall(r'"view_price":"([^"]+)"', text)
                        nids = re.findall(r'"nid":"([^"]+)"', text)
                        sales = re.findall(r'"view_sales":"([^"]+)"', text)
                        shops = re.findall(r'"nick":"([^"]+)"', text)

                        if titles and len(titles) > 0:
                            # print(f"   âœ… æˆåŠŸæå–åˆ° {len(titles)} æ¡è®°å½•")
                            for i in range(len(titles)):
                                price = prices[i] if i < len(prices) else "æœªçŸ¥"
                                nid = nids[i] if i < len(nids) else ""
                                sale = sales[i] if i < len(sales) else "0"
                                shop = shops[i] if i < len(shops) else "æœªçŸ¥åº—é“º"
                                title = titles[i]

                                # ç®€å•è¿‡æ»¤ï¼šæ ‡é¢˜å¿…é¡»åŒ…å«å…³é”®è¯çš„ä¸€éƒ¨åˆ† (é¿å…å®Œå…¨ä¸ç›¸å…³çš„æ¨è)
                                # å¦‚æœå…³é”®è¯å¾ˆé•¿ï¼Œå–å‰ä¸¤ä¸ªå­—
                                # filter_key = self.keyword[:2] if len(self.keyword) >= 2 else self.keyword
                                # if filter_key and filter_key not in title:
                                #    continue

                                if nid and not any(p['id'] == nid for p in self.global_products):
                                    self.global_products.append({
                                        "id": nid,
                                        "title": title,
                                        "price": price,
                                        "link": f"https://item.taobao.com/item.htm?id={nid}",
                                        "shop": shop,
                                        "deal_count": sale
                                    })

            except Exception:
                pass

    def _extract_from_dom(self, page):
        """
        å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥ä»é¡µé¢ DOM æå–å•†å“ä¿¡æ¯
        """
        print("   âš ï¸ ç½‘ç»œæ‹¦æˆªæ•°æ®ä¸è¶³ï¼Œå°è¯•ä»é¡µé¢å…ƒç´ æå–...")
        try:
            # è°ƒè¯•ï¼šæ‰“å°é¡µé¢å†…å®¹çš„ä¸€å°éƒ¨åˆ†ï¼Œçœ‹çœ‹æ˜¯å¦åŠ è½½äº†éªŒè¯ç æˆ–è€…ç©ºé¡µé¢
            content = page.content()
            if "éªŒè¯ç " in content or "baxia-dialog" in content:
                print("   ğŸš¨ æ£€æµ‹åˆ°éªŒè¯ç æ‹¦æˆªï¼")
            elif "æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å®è´" in content:
                print("   âš ï¸ é¡µé¢æ˜¾ç¤ºæ²¡æœ‰æ‰¾åˆ°ç›¸å…³å®è´")
            
            # æŸ¥æ‰¾æ‰€æœ‰åŒ…å« item.htm çš„é“¾æ¥ (è¿™æ˜¯æ·˜å®å•†å“çš„ç‰¹å¾)
            # æ·˜å®çš„å•†å“å¡ç‰‡é€šå¸¸åŒ…å«ä¸€ä¸ªæŒ‡å‘ item.htm çš„é“¾æ¥
            # å°è¯•æ›´å®½æ³›çš„é€‰æ‹©å™¨
            items = page.query_selector_all('a')
            
            # å»é‡ ID
            seen_ids = set(p['id'] for p in self.global_products)
            
            count = 0
            for item in items:
                try:
                    href = item.get_attribute("href")
                    if not href or "item.htm" not in href: continue
                    
                    # æå– ID
                    match = re.search(r'id=(\d+)', href)
                    if not match: continue
                    nid = match.group(1)
                    
                    if nid in seen_ids: continue
                    
                    # å°è¯•è·å–æ ‡é¢˜
                    # ç­–ç•¥1: å›¾ç‰‡çš„ alt å±æ€§
                    title = ""
                    img = item.query_selector("img")
                    if img:
                        title = img.get_attribute("alt")
                    
                    # ç­–ç•¥2: é“¾æ¥æœ¬èº«çš„æ–‡æœ¬
                    if not title:
                        title = item.inner_text().strip()
                        
                    # ç­–ç•¥3: å°è¯•æ‰¾é™„è¿‘çš„æ ‡é¢˜å…ƒç´  (å‘ä¸Šæ‰¾çˆ¶çº§å†æ‰¾æ–‡æœ¬)
                    if not title or len(title) < 5:
                        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å‡è®¾ï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„éå†
                        pass

                    # ä»·æ ¼æå– (å°è¯•åœ¨çˆ¶çº§æ–‡æœ¬ä¸­æ‰¾ Â¥)
                    price = "æœªçŸ¥"
                    try:
                        # å‘ä¸Šæ‰¾å‡ å±‚ï¼Œç›´åˆ°æ‰¾åˆ°åŒ…å«ä»·æ ¼çš„å®¹å™¨
                        parent = item
                        for _ in range(5):
                            parent = parent.query_selector("xpath=..")
                            if not parent: break
                            parent_text = parent.inner_text()
                            if "Â¥" in parent_text:
                                price_match = re.search(r'Â¥\s*([\d\.]+)', parent_text)
                                if price_match:
                                    price = price_match.group(1)
                                    break
                    except:
                        pass

                    # è¿‡æ»¤
                    filter_key = self.keyword[:2] if len(self.keyword) >= 2 else self.keyword
                    # å®½æ¾è¿‡æ»¤ï¼šåªè¦åŒ…å«å…³é”®è¯çš„ä¸€ä¸ªå­—ï¼Œæˆ–è€…æ ‡é¢˜å¾ˆé•¿ä¸”åŒ…å«ç›¸å…³è¯
                    # è¿™é‡Œæˆ‘ä»¬ç¨å¾®æ”¾å®½ä¸€ç‚¹ï¼Œå› ä¸º DOM æå–çš„æ ‡é¢˜å¯èƒ½ä¸å®Œæ•´
                    # if filter_key and filter_key not in title:
                        # å°è¯•æ›´å®½æ¾çš„åŒ¹é…
                        # if len(self.keyword) > 0 and self.keyword[0] in title:
                             # pass # å…è®¸
                        # else:
                             # print(f"   ğŸ—‘ï¸ è¿‡æ»¤æ‰æ— å…³å•†å“: {title}")
                             # continue

                    if title:
                        link = href if href.startswith("http") else "https:" + href
                        self.global_products.append({
                            "id": nid,
                            "title": title,
                            "price": price,
                            "link": link,
                            "shop": "æ·˜å®åº—é“º", # DOM éš¾æå–ï¼Œæš‚ä¸”é»˜è®¤
                            "deal_count": "æœªçŸ¥"
                        })
                        seen_ids.add(nid)
                        count += 1
                except:
                    continue
            
            if count > 0:
                print(f"   âœ… é€šè¿‡é¡µé¢å…ƒç´ è¡¥å……äº† {count} ä¸ªå•†å“")
            else:
                print("   âŒ DOM æå–ä¹Ÿæœªæ‰¾åˆ°å•†å“ï¼Œå¯èƒ½æ˜¯é¡µé¢ç»“æ„å˜åŒ–æˆ–åçˆ¬è™«")
                # å°è¯•æ‰“å°é¡µé¢ä¸Šçš„æ‰€æœ‰é“¾æ¥ï¼Œçœ‹çœ‹æœ‰æ²¡æœ‰ item.htm
                # links = [l.get_attribute("href") for l in items if l.get_attribute("href") and "item.htm" in l.get_attribute("href")]
                # print(f"   ğŸ” é¡µé¢ä¸ŠåŒ…å« item.htm çš„é“¾æ¥æ•°: {len(links)}")
                
        except Exception as e:
            print(f"   âŒ DOM æå–å¤±è´¥: {e}")

    def search(self, keyword, max_pages=3):
        self.global_products = []
        self.keyword = keyword
        
        with sync_playwright() as p:
            # âš ï¸ ä¸¥é‡è­¦å‘Šï¼šæ·˜å®å¯¹ Headless æ¨¡å¼æ£€æµ‹æä¸¥ï¼Œå¿…é¡»ä½¿ç”¨æœ‰å¤´æ¨¡å¼ (headless=False)
            # å¦åˆ™ææ˜“è§¦å‘é£æ§ï¼Œå¯¼è‡´è´¦å·è¢«é™åˆ¶
            browser = p.chromium.launch(
                headless=False, 
                args=[
                    "--disable-blink-features=AutomationControlled",
                    "--no-sandbox",
                    "--disable-infobars",
                    "--window-size=1280,800",
                    "--disable-extensions"
                ],
                ignore_default_args=["--enable-automation"]
            )
            
            auth_file = "auth.json"
            context_args = {
                "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
                "viewport": {"width": 1280, "height": 800},
                "device_scale_factor": 1,
            }
            
            # 1. ç™»å½•æŒä¹…åŒ–é€»è¾‘ä¼˜åŒ–
            if os.path.exists(auth_file):
                print("ğŸ”‘ [ç³»ç»Ÿ] åŠ è½½å†å²ç™»å½•å‡­è¯...")
                context_args["storage_state"] = auth_file
            
            context = browser.new_context(**context_args)
            
            # æ³¨å…¥å¼ºåŠ›é˜²æ£€æµ‹è„šæœ¬
            context.add_init_script("""
                Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
                window.navigator.chrome = { runtime: {} };
                Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});
            """)
            
            page = context.new_page()
            # å¼€å¯è¯·æ±‚æ‹¦æˆªï¼Œç”¨äºè·å– API æ•°æ®
            page.on("response", self._handle_search_response)

            print("ğŸš€ [æ·˜å®] æ­£åœ¨è¿æ¥...")
            try:
                page.goto("https://www.taobao.com/", timeout=30000)
            except:
                print("   âš ï¸ é¦–é¡µåŠ è½½è¶…æ—¶ï¼Œå°è¯•ç›´æ¥æœç´¢...")

            # 2. æ™ºèƒ½ç™»å½•æ£€æµ‹
            # å¦‚æœè·³è½¬åˆ°äº† login.taobao.com æˆ–è€…é¡µé¢ä¸Šæœ‰ç™»å½•æ¡†
            if "login.taobao.com" in page.url or page.query_selector(".login-btn") or page.query_selector("a.h-login"):
                print("ğŸ”” [éœ€è¦ç™»å½•] å‡­è¯å·²è¿‡æœŸæˆ–ä¸å­˜åœ¨ã€‚")
                print("ğŸ‘‰ è¯·åœ¨å¼¹å‡ºçš„æµè§ˆå™¨ä¸­æ‰«ç ç™»å½•ã€‚")
                
                try:
                    # ç­‰å¾…ç›´åˆ°ä¸å†æ˜¯ç™»å½•é¡µ
                    page.wait_for_url(lambda u: "login" not in u, timeout=300000) # 5åˆ†é’Ÿç­‰å¾…æ—¶é—´
                    print("âœ… æ£€æµ‹åˆ°ç™»å½•æˆåŠŸï¼")
                    # ä¿å­˜æ–°çš„å‡­è¯
                    context.storage_state(path=auth_file)
                    print("ğŸ’¾ æ–°çš„ç™»å½•çŠ¶æ€å·²ä¿å­˜ã€‚")
                except:
                    print("âŒ ç™»å½•è¶…æ—¶ï¼Œç¨‹åºå¯èƒ½æ— æ³•è·å–æ•°æ®ã€‚")

            for page_num in range(1, max_pages + 1):
                # ğŸ›¡ï¸ å®‰å…¨å»¶è¿Ÿï¼šæ¯é¡µä¹‹é—´éšæœºæš‚åœï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸ºï¼Œé˜²æ­¢è§¦å‘é£æ§
                if page_num > 1:
                    sleep_time = random.uniform(3, 6)
                    print(f"   ğŸ’¤ ä¼‘æ¯ {sleep_time:.1f} ç§’ä»¥é˜²æ£€æµ‹...")
                    time.sleep(sleep_time)

                offset = (page_num - 1) * 44
                search_url = f"https://s.taobao.com/search?q={keyword}&s={offset}"
                
                print(f"ğŸš€ [ç¬¬ {page_num}/{max_pages} é¡µ] æ­£åœ¨æœç´¢: {keyword}")
                
                try:
                    page.goto(search_url, timeout=60000)
                    
                    # 3. åçˆ¬è™«æ£€æµ‹ (æ»‘å—/éªŒè¯ç /é£æ§)
                    content = page.content()
                    if "baxia-dialog" in content or "éªŒè¯ç " in content or "punish" in page.url:
                        print("ğŸš¨ [ä¸¥é‡è­¦å‘Š] è§¦å‘äº†æ·˜å®é£æ§éªŒè¯ï¼")
                        print("ğŸ‘‰ è¯·æ‰‹åŠ¨åœ¨æµè§ˆå™¨ä¸­å®Œæˆæ»‘å—éªŒè¯æˆ–è§£é™¤é™åˆ¶...")
                        # æ’­æ”¾æç¤ºéŸ³ (Windows)
                        print("\a") 
                        input("âœ… éªŒè¯å®Œæˆåï¼Œè¯·åŠ¡å¿…æŒ‰ [å›è½¦] ç»§ç»­...")
                    
                    # ç­‰å¾…å•†å“åˆ—è¡¨åŠ è½½
                    try:
                        # å°è¯•ç­‰å¾…å•†å“å®¹å™¨
                        page.wait_for_selector("div[class*='Content--contentInner']", timeout=10000)
                    except:
                        pass

                    # æ¨¡æ‹Ÿå¿«é€Ÿæµè§ˆ (è§¦å‘æ‡’åŠ è½½)
                    page.evaluate("window.scrollTo(0, document.body.scrollHeight/2)")
                    time.sleep(1)
                    page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                    time.sleep(1)
                    
                    # 4. å¤šé‡æ•°æ®æå–ç­–ç•¥
                    current_count = len(self.global_products)
                    
                    # ç­–ç•¥ A: ç½‘ç»œæ‹¦æˆª (å·²é€šè¿‡ page.on è‡ªåŠ¨æ‰§è¡Œ)
                    
                    # ç­–ç•¥ B: é¡µé¢è„šæœ¬æ•°æ®æå– (æœ€å¿«ï¼Œæœ€å…¨)
                    if len(self.global_products) == current_count:
                        self._extract_from_script_data(page)
                    
                    # ç­–ç•¥ C: DOM æš´åŠ›æå– (å…œåº•)
                    if len(self.global_products) == current_count:
                        self._extract_from_dom_desktop(page)
                        
                    new_count = len(self.global_products) - current_count
                    print(f"   ğŸ“Š æœ¬é¡µæ–°å¢: {new_count} ä¸ªå•†å“")
                    
                except Exception as e:
                    print(f"   âŒ æœ¬é¡µæŠ“å–å¼‚å¸¸: {e}")

            page.remove_listener("response", self._handle_search_response)
            browser.close()
            
        return self.global_products

    def _extract_from_script_data(self, page):
        """
        ä»é¡µé¢åµŒå…¥çš„ JSON æ•°æ®ä¸­æå– (g_page_config)
        è¿™æ˜¯æ·˜å®æœ€å¿«çš„æ•°æ®æºï¼Œä¸éœ€è¦è§£æ DOM
        """
        print("   âš¡ å°è¯•ä»é¡µé¢è„šæœ¬æå–æ•°æ®...")
        try:
            # å°è¯•æ‰§è¡Œ JS è·å– g_page_config
            data = page.evaluate("() => { return window.g_page_config; }")
            if data and "mods" in data:
                itemlist = data["mods"].get("itemlist", {}).get("data", {}).get("auctions", [])
                count = 0
                seen_ids = set(p['id'] for p in self.global_products)
                
                for item in itemlist:
                    nid = item.get("nid")
                    if not nid or nid in seen_ids: continue
                    
                    title = item.get("raw_title", "")
                    price = item.get("view_price", "0")
                    sales = item.get("view_sales", "0")
                    pic = item.get("pic_url", "")
                    link = item.get("detail_url", "")
                    
                    # è¿‡æ»¤
                    # if self.keyword[:2] not in title: continue
                    
                    self.global_products.append({
                        "id": nid,
                        "title": title,
                        "price": price,
                        "link": link if link.startswith("http") else "https:" + link,
                        "shop": item.get("nick", "æ·˜å®åº—é“º"),
                        "deal_count": sales
                    })
                    seen_ids.add(nid)
                    count += 1
                
                if count > 0:
                    print(f"   âœ… é€šè¿‡è„šæœ¬æ•°æ®æå–äº† {count} ä¸ªå•†å“")
                    return
        except:
            pass

    def _extract_from_dom_desktop(self, page):
        """
        æ¡Œé¢ç«¯ DOM æå– (é€šç”¨å…œåº•ç‰ˆ)
        """
        print("   âš ï¸ å°è¯•é€šç”¨ DOM æå–...")
        
        # è°ƒè¯•ä¿¡æ¯ï¼šå¦‚æœé¡µé¢å¼‚å¸¸ï¼Œæ‰“å°å‡ºæ¥
        title = page.title()
        if "ç™»å½•" in title or "éªŒè¯" in title:
             print(f"   ğŸš¨ é¡µé¢çŠ¶æ€å¼‚å¸¸: {title}")
        
        try:
            # å¯»æ‰¾æ‰€æœ‰å¸¦ item.htm çš„é“¾æ¥
            items = page.query_selector_all("a[href*='item.htm']")
            if not items:
                 print(f"   ğŸ” æœªæ‰¾åˆ°å•†å“é“¾æ¥ã€‚å½“å‰é¡µé¢æ ‡é¢˜: {title}")
                 # å°è¯•æ‰“å°é¡µé¢æ–‡æœ¬çš„å‰ 100 ä¸ªå­—ç¬¦
                 # print(f"   ğŸ“„ é¡µé¢å†…å®¹æ‘˜è¦: {page.inner_text()[:100]}")

            seen_ids = set(p['id'] for p in self.global_products)
            count = 0
            
            for item in items:
                try:
                    href = item.get_attribute("href")
                    # æå– ID
                    match = re.search(r'id=(\d+)', href)
                    if not match: continue
                    nid = match.group(1)
                    if nid in seen_ids: continue
                    
                    # å°è¯•è·å–åŒ…å«è¯¥é“¾æ¥çš„æ•´ä¸ªå¡ç‰‡å®¹å™¨
                    # å‘ä¸Šæ‰¾ 3-4 å±‚
                    card = item
                    found_price = False
                    price = "æœªçŸ¥"
                    title = ""
                    
                    # ç®€å•çš„å‘ä¸ŠæŸ¥æ‰¾é€»è¾‘
                    for _ in range(5):
                        parent = card.query_selector("xpath=..")
                        if not parent: break
                        card = parent
                        text = card.inner_text()
                        if "Â¥" in text or "ï¿¥" in text:
                            found_price = True
                            # æå–ä»·æ ¼
                            p_match = re.search(r'[Â¥ï¿¥]\s*([\d\.]+)', text)
                            if p_match: price = p_match.group(1)
                            
                            # æå–æ ‡é¢˜ (æ’é™¤ä»·æ ¼åçš„æœ€é•¿æ–‡æœ¬)
                            lines = text.split('\n')
                            valid_lines = [l for l in lines if len(l) > 5 and 'Â¥' not in l]
                            if valid_lines:
                                title = max(valid_lines, key=len)
                            break
                    
                    if not found_price: continue
                    
                    # å®½æ¾è¿‡æ»¤
                    # if self.keyword[:1] not in title: continue

                    self.global_products.append({
                        "id": nid,
                        "title": title,
                        "price": price,
                        "link": href if href.startswith("http") else "https:" + href,
                        "shop": "æ·˜å®åº—é“º",
                        "deal_count": "æœªçŸ¥"
                    })
                    seen_ids.add(nid)
                    count += 1
                except:
                    continue
            
            if count > 0:
                print(f"   âœ… é€šè¿‡ DOM æå–äº† {count} ä¸ªå•†å“")
                
        except Exception as e:
            print(f"   âŒ DOM æå–å¤±è´¥: {e}")

    def _handle_detail_response(self, response):
        try:
            url = response.url
            if "rate" in url or "detail" in url or "mtop" in url:
                content_type = response.headers.get("content-type", "")
                if "json" in content_type or "javascript" in content_type:
                    text = response.text()
                    
                    if text.strip().startswith("mtopjsonp") or text.strip().startswith("jsonp"):
                        match = re.search(r'\((.*)\)', text)
                        if match:
                            text = match.group(1)
                    
                    try:
                        data = json.loads(text)
                        
                        if "rateList" in text or "rateDetail" in text:
                            if "rateList" not in self.global_details:
                                self.global_details["rateList"] = []
                            
                            rate_list = data.get("data", {}).get("rateDetail", {}).get("rateList", [])
                            if rate_list:
                                print(f"   ğŸ’¬ æ•è·åˆ° {len(rate_list)} æ¡è¯„è®ºæ•°æ®")
                                self.global_details["rateList"].extend(rate_list)

                        if "item" in text and "props" in text:
                             if "itemProps" not in self.global_details:
                                 self.global_details["itemProps"] = {}
                             
                             props = data.get("data", {}).get("item", {}).get("props", [])
                             if props:
                                 print(f"   ğŸ“ æ•è·åˆ°å•†å“å‚æ•°æ•°æ®")
                                 self.global_details["itemProps"] = props

                    except:
                        pass
        except:
            pass

    def get_details(self, candidates):
        """
        æ·±åº¦é‡‡é›† (æ¡Œé¢ç«¯)
        """
        if not candidates:
            return

        print(f"ğŸš€ å¼€å§‹æ·±åº¦é‡‡é›† {len(candidates)} ä¸ªç²¾é€‰å•†å“ (æ¡Œé¢ç«¯æ¨¡å¼)...")
        os.makedirs("data/details", exist_ok=True)

        with sync_playwright() as p:
            browser = p.chromium.launch(
                headless=False,
                args=[
                    "--disable-blink-features=AutomationControlled",
                    "--no-sandbox",
                    "--disable-infobars",
                    "--window-size=1280,800",
                    "--disable-extensions"
                ],
                ignore_default_args=["--enable-automation"]
            )
            
            auth_file = "auth.json"
            context_args = {
                "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
                "viewport": {"width": 1280, "height": 800},
                "device_scale_factor": 1,
            }
            
            if os.path.exists(auth_file):
                context_args["storage_state"] = auth_file
                
            context = browser.new_context(**context_args)
            
            context.add_init_script("""
                Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
                window.navigator.chrome = { runtime: {} };
            """)

            page = context.new_page()
            page.on("response", self._handle_detail_response)

            # æ£€æŸ¥ç™»å½•
            try:
                page.goto("https://www.taobao.com/")
                time.sleep(2)
                if "login" in page.url or page.query_selector(".login-btn") or page.query_selector("a.h-login"):
                     print("ğŸ”” [è¯·æ³¨æ„]ï¼šè¯¦æƒ…é¡µé‡‡é›†ä¹Ÿéœ€è¦ç™»å½•ã€‚")
                     input("âœ… ç™»å½•å®Œæˆåï¼Œè¯·åœ¨æ§åˆ¶å°æŒ‰ [å›è½¦] é”®ç»§ç»­...")
                     context.storage_state(path=auth_file)
            except:
                pass

            for i, item in enumerate(candidates):
                self.global_details = {"rateList": [], "itemProps": []}
                
                url = item['link']
                print(f"ğŸ”„ [{i+1}/{len(candidates)}] æ­£åœ¨æ·±åº¦æŠ“å–: {item['title'][:20]}...")
                
                try:
                    if not url.startswith("http"):
                        url = "https:" + url
                    
                    page.goto(url, timeout=60000)
                    time.sleep(3)
                    
                    # æ¨¡æ‹Ÿæ»šåŠ¨
                    page.mouse.wheel(0, 1000)
                    time.sleep(1)
                    
                    # å°è¯•ç‚¹å‡»â€œç´¯è®¡è¯„ä»·â€ (æ¡Œé¢ç«¯)
                    try:
                        # å¯»æ‰¾åŒ…å«â€œè¯„ä»·â€çš„ Tab
                        # æ·˜å®æ¡Œé¢ç«¯é€šå¸¸æ˜¯ <a ...>ç´¯è®¡è¯„ä»· <span ...>...</span></a>
                        page.click("a:has-text('ç´¯è®¡è¯„ä»·')", timeout=3000)
                        time.sleep(2)
                    except:
                        pass
                    
                    # DOM æå–å‚æ•° (æ¡Œé¢ç«¯)
                    captured_props = self.global_details.get("itemProps", [])
                    if not captured_props:
                        try:
                            # æ¡Œé¢ç«¯å‚æ•°é€šå¸¸åœ¨ ul.attributes-list
                            props_el = page.query_selector("ul.attributes-list")
                            if props_el:
                                items = props_el.query_selector_all("li")
                                captured_props = [{"name": "å‚æ•°", "value": li.inner_text()} for li in items]
                            else:
                                # å¤‡ç”¨ï¼šå°è¯•æ‰¾ .tm-table-view (å¤©çŒ«)
                                items = page.query_selector_all(".tm-table-view tr")
                                for tr in items:
                                    text = tr.inner_text().replace('\n', ':')
                                    captured_props.append({"name": "å‚æ•°", "value": text})
                        except:
                            pass

                    # DOM æå–è¯„è®º (æ¡Œé¢ç«¯)
                    captured_reviews = self.global_details.get("rateList", [])
                    if not captured_reviews:
                        try:
                            # å°è¯•æå–è¯„è®ºæ–‡æœ¬
                            # æ·˜å®è¯„è®ºé€šå¸¸åœ¨ .tm-rate-content
                            reviews = page.query_selector_all(".tm-rate-content, .review-content")
                            for r in reviews[:10]:
                                captured_reviews.append({"content": r.inner_text()})
                        except:
                            pass

                    detail_data = {
                        "id": item['id'],
                        "title": item['title'],
                        "price": item['price'],
                        "shop": item['shop'],
                        "captured_reviews": captured_reviews,
                        "captured_props": captured_props
                    }
                    
                    file_name = f"data/details/{item['id']}.json"
                    with open(file_name, "w", encoding="utf-8") as f:
                        json.dump(detail_data, f, ensure_ascii=False, indent=2)
                    
                    print(f"   âœ… å·²ä¿å­˜è¯¦æƒ…æ•°æ®: {file_name}")
                    
                except Exception as e:
                    print(f"   âŒ æŠ“å–å¤±è´¥: {e}")

            browser.close()
